{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras import backend as K\n",
    "import numpy as np \n",
    "from matplotlib.pyplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 2\n",
    "n_support,n_query = 3,2\n",
    "emb_size =2\n",
    "\n",
    "emb_np_raw = np.random.uniform(0,1,size=(n_way*(n_support+n_query),emb_size ) )\n",
    "emb = K.identity(emb_np_raw)\n",
    "#embemb_np_raw_l2 =K.eval( K.l2_normalize(emb,axis=1))\n",
    "y_np = [i for i in range(n_way)]* n_support + [i for i in range(n_way)]*n_query\n",
    "y = K.identity(y_np)\n",
    "embemb_np_raw_l2=emb_np_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "def euc_distance(a,b):\n",
    "    M2=b.shape[0]\n",
    "    M1=a.shape[0]\n",
    "    p1 = tf.matmul(tf.expand_dims(tf.reduce_sum(tf.square(a), 1), 1),tf.ones(shape=(1, M2),dtype=tf.float64) )\n",
    "    p2 = tf.transpose(tf.matmul(tf.reshape(tf.reduce_sum(tf.square(b), 1), \n",
    "                                           shape=[-1, 1]),tf.ones(shape=(M1, 1),\n",
    "                                           dtype=tf.float64),transpose_b=True))\n",
    "    res = tf.add(p1, p2) - 2 * K.dot(a, K.transpose(b))\n",
    "    return res\n",
    "\n",
    "\n",
    "def euc_distance1(a,b):\n",
    "    \n",
    "    row_norms_A = tf.reduce_sum(tf.square(a), axis=1)\n",
    "    row_norms_A = tf.reshape(row_norms_A, [-1, 1])  # Column vector.\n",
    "\n",
    "    row_norms_B = tf.reduce_sum(tf.square(b), axis=1)\n",
    "    row_norms_B = tf.reshape(row_norms_B, [1, -1])  # Row vector.\n",
    "\n",
    "    return row_norms_A - 2 * tf.matmul(a, tf.transpose(b)) + row_norms_B\n",
    "\n",
    "def proto_loss(emb,y_input):\n",
    "    emb_s = emb[0:n_way*n_support,:]\n",
    "    emb_q = emb[n_way*n_support:,:]    \n",
    "    y_s = K.gather(y_input, [i for i in range(n_way*n_support)])\n",
    "    y_q = K.gather(y_input, [i for i in range(n_way*n_support, n_way*(n_support+n_query)) ])\n",
    "    \n",
    "    onehot_s = K.cast(K.one_hot(y_s, n_way),'float64')\n",
    "    centers = K.dot(K.transpose(onehot_s), emb_s)/n_support \n",
    "    dist_1=euc_distance1(emb_q,centers)\n",
    "    onehot_q = K.cast(K.one_hot(y_q, n_way),'bool')\n",
    "    loss_deno = K.logsumexp(-1 * dist_1,axis=1)\n",
    "    loss_nume = tf.boolean_mask(dist_1, onehot_q)\n",
    "    \n",
    "    loss = K.mean(loss_nume + loss_deno)\n",
    "    return loss \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7062270962917749\n",
      "0.706227096291775\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    '''\n",
    "    Compute euclidean distance between two tensors\n",
    "    '''\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    if d != y.size(1):\n",
    "        raise Exception\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "\n",
    "def prototypical_loss(input, target, n_support):\n",
    "    '''\n",
    "    Inspired by https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "    Compute the barycentres by averaging the features of n_support\n",
    "    samples for each class in target, computes then the distances from each\n",
    "    samples' features to each one of the barycentres, computes the\n",
    "    log_probability for each n_query samples for each one of the current\n",
    "    classes, of appartaining to a class c, loss and accuracy are then computed\n",
    "    and returned\n",
    "    Args:\n",
    "    - input: the model output for a batch of samples\n",
    "    - target: ground truth for the above batch of samples\n",
    "    - n_support: number of samples to keep in account when computing\n",
    "      barycentres, for each one of the current classes\n",
    "    '''\n",
    "    target_cpu = target.to('cpu')\n",
    "    input_cpu = input.to('cpu')\n",
    "\n",
    "    def supp_idxs(c):\n",
    "        # FIXME when torch will support where as np\n",
    "        return target_cpu.eq(c).nonzero()[:n_support].squeeze(1)\n",
    "\n",
    "    # FIXME when torch.unique will be available on cuda too\n",
    "    classes = torch.unique(target_cpu)\n",
    "    n_classes = len(classes)\n",
    "    # FIXME when torch will support where as np\n",
    "    # assuming n_query, n_target constants\n",
    "    n_query = target_cpu.eq(classes[0].item()).sum().item() - n_support\n",
    "\n",
    "    support_idxs = list(map(supp_idxs, classes))\n",
    "    #print('support_idxs',support_idxs)\n",
    "    prototypes = torch.stack([input_cpu[idx_list].mean(0) for idx_list in support_idxs])\n",
    "    # FIXME when torch will support where as np\n",
    "    #print(prototypes)\n",
    "    query_idxs = torch.stack(list(map(lambda c: target_cpu.eq(c).nonzero()[n_support:], classes))).view(-1)\n",
    "    #print('query_idxs',query_idxs)\n",
    "    query_samples = input.to('cpu')[query_idxs]\n",
    "    #print(\"prototypes\",prototypes)\n",
    "    #print(\"query_samples\",query_samples)\n",
    "    \n",
    "    dists = euclidean_dist(query_samples, prototypes)\n",
    "    #print(\"dists\",dists)\n",
    "    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n",
    "    \n",
    "    target_inds = torch.arange(0, n_classes)\n",
    "    target_inds = target_inds.view(n_classes, 1, 1)\n",
    "    target_inds = target_inds.expand(n_classes, n_query, 1).long()\n",
    "\n",
    "    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "    _, y_hat = log_p_y.max(2)\n",
    "    acc_val = y_hat.eq(target_inds.squeeze()).float().mean()\n",
    "\n",
    "    return loss_val,  acc_val\n",
    "l, a =prototypical_loss(torch.tensor(embemb_np_raw_l2),torch.tensor(y_np),n_support)\n",
    "print(l.numpy().item())\n",
    "print(K.eval(proto_loss(emb,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.88178420e-16  3.33066907e-15  3.10862447e-15  0.00000000e+00\n",
      " -2.22044605e-16  4.44089210e-16 -2.22044605e-16  2.22044605e-16\n",
      "  1.55431223e-15 -3.99680289e-15  3.33066907e-16  1.11022302e-16\n",
      "  0.00000000e+00 -4.44089210e-16 -6.66133815e-16 -3.10862447e-15\n",
      "  1.33226763e-15  5.55111512e-15  8.88178420e-16 -8.88178420e-16\n",
      " -2.22044605e-16 -8.88178420e-16  1.55431223e-15  0.00000000e+00\n",
      " -7.77156117e-16 -1.11022302e-15 -5.55111512e-16 -1.11022302e-15\n",
      " -2.22044605e-16 -1.11022302e-15  0.00000000e+00  1.11022302e-16\n",
      " -6.66133815e-16  1.11022302e-15 -1.55431223e-15 -6.66133815e-16\n",
      " -2.22044605e-16 -4.44089210e-16  5.55111512e-16 -4.44089210e-16\n",
      "  3.33066907e-16  3.10862447e-15 -2.22044605e-16 -2.22044605e-16\n",
      "  0.00000000e+00 -2.22044605e-16  8.88178420e-16  3.33066907e-16\n",
      " -2.22044605e-16  5.55111512e-16]\n",
      "[39, 65, 86, 13, 75, 42, 54, 20, 63, 95, 33, 8, 62, 54, 39, 97, 43, 77, 89, 56, 46, 86, 48, 6, 54, 70, 48, 61, 28, 23, 49, 48, 34, 25, 37, 44, 12, 61, 43, 21, 36, 96, 30, 13, 39, 50, 49, 26, 24, 27]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12f2af978>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/SQyfDAZhA8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f1a16d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k =[]\n",
    "p =[]\n",
    "e=[]\n",
    "for i in range(50):\n",
    "    emb_size=np.random.randint(6,100)\n",
    "    e.append(emb_size)\n",
    "    emb_np_raw = np.random.uniform(0,1,size=(n_way*(n_support+n_query),emb_size ) )\n",
    "    emb = K.identity(emb_np_raw)\n",
    "    #embemb_np_raw_l2 =K.eval( K.l2_normalize(emb,axis=1))\n",
    "    embemb_np_raw_l2=emb_np_raw\n",
    "    y_np = [i for i in range(n_way)]* n_support + [i for i in range(n_way)]*n_query\n",
    "    y = K.identity(y_np)\n",
    "    k.append(K.eval(proto_loss(emb,y)))\n",
    "    l, a =prototypical_loss(torch.tensor(embemb_np_raw_l2),torch.tensor(y_np),n_support)\n",
    "    p.append(l.numpy().item())\n",
    "    \n",
    "\n",
    "\n",
    "print(np.array(k)-np.array(p))\n",
    "print(e)\n",
    "plot(k,p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
